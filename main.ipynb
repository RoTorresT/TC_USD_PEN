{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled113.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled113.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYIdgaTxVHXw"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "import os\n",
        "import re\n",
        "import json"
      ],
      "execution_count": 360,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_KxV4-5Vqpx"
      },
      "source": [
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duc2aAB0VttB",
        "outputId": "03b7f06c-9bb1-4b11-adb5-761627cb411b"
      },
      "source": [
        "wd = webdriver.Chrome('chromedriver',options=options)\n",
        "\n",
        "# open it, go to a website, and get results\n",
        "\n",
        "date = datetime.now()-timedelta(hours = 5)\n",
        "\n",
        "wd.get('https://cuantoestaeldolar.pe')\n",
        "page_source = wd.page_source\n",
        "wd.quit\n",
        "\n",
        "soup = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "#extract casas de cambio\n",
        "\n",
        "date = datetime.now()-timedelta(hours = 5)\n",
        "\n",
        "x = soup.find('div', attrs = {'class' : 'clear-fix block-online-change'})\n",
        "x = x.find_all('div', attrs = {'class' : 'wrapper-table tb_dollar'})\n",
        "\n",
        "x = [w.get_text() for w in x]\n",
        "x = [w.strip() for w in x]\n",
        "\n",
        "x = x[::2]\n",
        "x = [w.replace('\\n', '') for w in x ]\n",
        "x = [w.split('Cambiar') for w in x ]\n",
        "\n",
        "datetime_str = date.strftime(\"%Y_%m_%d-%I_%M_%S\")\n",
        "\n",
        "info_now = {}\n",
        "info_now[datetime_str] = {}\n",
        "\n",
        "for i in x:\n",
        "  info_now[datetime_str][i[0]] = {}\n",
        "  \n",
        "  compra_aux = re.findall('^\\d.\\d?\\d?\\d?\\d', i[1])\n",
        "  info_now[datetime_str][i[0]][\"compra\"] = float(compra_aux[0])\n",
        "\n",
        "  venta_aux = re.findall('\\d.\\d?\\d?\\d?\\d?\\d$', i[1])\n",
        "  info_now[datetime_str][i[0]][\"venta\"] = float(venta_aux[0])\n",
        "\n",
        "if os.path.exists('r/r.json'):\n",
        "\n",
        "  with open('r/r.json', 'r') as f:\n",
        "    loaded_data = json.load(f)\n",
        "\n",
        "  loaded_data.update(info_now)\n",
        "\n",
        "  with open('r/r.json', 'w') as f:\n",
        "    json.dump(loaded_data, f)\n",
        "\n",
        "  print('ga1')\n",
        "\n",
        "\n",
        "else:\n",
        "  os.mkdir('r/')\n",
        "  with open('r/r.json', 'w') as f:\n",
        "    json.dump(info_now, f)\n",
        "\n",
        "  print('ga')"
      ],
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ga1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
        "id": "PGo-aYZSVL0M",
        "outputId": "66ad901f-6b1b-41f2-9d4c-88efafdce7be"
      },
      "source": [
        "!pip install fake-headers\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fake-headers in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from fake-headers) (0.0.1)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.7/dist-packages (from fake-headers) (1.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->fake-headers) (4.6.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from html5lib->fake-headers) (0.5.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from html5lib->fake-headers) (1.15.0)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [62.9 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Ign:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [695 kB]\n",
            "Get:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [510 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,263 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,786 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,420 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.7 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [544 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [39.4 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,698 kB]\n",
            "Get:26 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [914 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,195 kB]\n",
            "Get:28 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.1 kB]\n",
            "Fetched 13.5 MB in 5s (2,926 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 98 not upgraded.\n",
            "Need to get 86.0 MB of archives.\n",
            "After this operation, 298 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 91.0.4472.101-0ubuntu0.18.04.1 [1,124 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 91.0.4472.101-0ubuntu0.18.04.1 [76.1 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 91.0.4472.101-0ubuntu0.18.04.1 [3,937 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 91.0.4472.101-0ubuntu0.18.04.1 [4,837 kB]\n",
            "Fetched 86.0 MB in 6s (15.5 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 160837 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_91.0.4472.101-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Collecting selenium\n",
            "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
            "\u001b[K     |████████████████████████████████| 904 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYIdgaTxVHXw"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "import os\n",
        "import re\n",
        "import json"
      ],
      "execution_count": 360,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_KxV4-5Vqpx"
      },
      "source": [
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duc2aAB0VttB",
        "outputId": "03b7f06c-9bb1-4b11-adb5-761627cb411b"
      },
      "source": [
        "wd = webdriver.Chrome('chromedriver',options=options)\n",
        "\n",
        "# open it, go to a website, and get results\n",
        "\n",
        "date = datetime.now()-timedelta(hours = 5)\n",
        "\n",
        "wd.get('https://cuantoestaeldolar.pe')\n",
        "page_source = wd.page_source\n",
        "wd.quit\n",
        "\n",
        "soup = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "#extract casas de cambio\n",
        "\n",
        "date = datetime.now()-timedelta(hours = 5)\n",
        "\n",
        "x = soup.find('div', attrs = {'class' : 'clear-fix block-online-change'})\n",
        "x = x.find_all('div', attrs = {'class' : 'wrapper-table tb_dollar'})\n",
        "\n",
        "x = [w.get_text() for w in x]\n",
        "x = [w.strip() for w in x]\n",
        "\n",
        "x = x[::2]\n",
        "x = [w.replace('\\n', '') for w in x ]\n",
        "x = [w.split('Cambiar') for w in x ]\n",
        "\n",
        "datetime_str = date.strftime(\"%Y_%m_%d-%I_%M_%S\")\n",
        "\n",
        "info_now = {}\n",
        "info_now[datetime_str] = {}\n",
        "\n",
        "for i in x:\n",
        "  info_now[datetime_str][i[0]] = {}\n",
        "  \n",
        "  compra_aux = re.findall('^\\d.\\d?\\d?\\d?\\d', i[1])\n",
        "  info_now[datetime_str][i[0]][\"compra\"] = float(compra_aux[0])\n",
        "\n",
        "  venta_aux = re.findall('\\d.\\d?\\d?\\d?\\d?\\d$', i[1])\n",
        "  info_now[datetime_str][i[0]][\"venta\"] = float(venta_aux[0])\n",
        "\n",
        "if os.path.exists('r/r.json'):\n",
        "\n",
        "  with open('r/r.json', 'r') as f:\n",
        "    loaded_data = json.load(f)\n",
        "\n",
        "  loaded_data.update(info_now)\n",
        "\n",
        "  with open('r/r.json', 'w') as f:\n",
        "    json.dump(loaded_data, f)\n",
        "\n",
        "  print('ga1')\n",
        "\n",
        "\n",
        "else:\n",
        "  os.mkdir('r/')\n",
        "  with open('r/r.json', 'w') as f:\n",
        "    json.dump(info_now, f)\n",
        "\n",
        "  print('ga')"
      ],
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ga1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
